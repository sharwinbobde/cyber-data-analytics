{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is how we will proceed\n",
    "- find unique `SrcAddr` and group by them\n",
    "- apply sliding window inside them\n",
    "- find ngrams(3-grams) in this sliding window\n",
    "\n",
    "Please wait for about 3-5mins for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:03<00:00,  9.69it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 14.63it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 166.20it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 131.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# reuse this module\n",
    "from profiling import profile_scenario\n",
    "\n",
    "selected_scenarios = [9, 10, 11, 12]\n",
    "\n",
    "ip_ngrams_per_scene= {}\n",
    "for scene in selected_scenarios:\n",
    "    ip_ngrams_per_scene[scene] = profile_scenario('data/utils/discretized_scenario_'+str(scene)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelled dictionary by IP and not discretised value :)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# read label encoder to convert encoded IPs to string\n",
    "\n",
    "SrcAddr_LabelEncoder_per_scene= {}\n",
    "for scene in selected_scenarios:\n",
    "    SrcAddr_LabelEncoder_per_scene[scene] = pickle.load(open('./data/utils/SrcAddr_LabelEncoder_'+str(scene)+'.pkl', 'rb'))\n",
    "\n",
    "\n",
    "try:\n",
    "    for scene in selected_scenarios:\n",
    "        keys = list(ip_ngrams_per_scene[scene].keys())\n",
    "        ip_keys = list(SrcAddr_LabelEncoder_per_scene[scene].inverse_transform(keys))\n",
    "        for i in range(len(ip_keys)):\n",
    "            ip_ngrams_per_scene[scene][ip_keys[i]] = ip_ngrams_per_scene[scene].pop(keys[i])\n",
    "finally:\n",
    "    print('Labelled dictionary by IP and not discretised value :)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now be able find all profiles for a scenario by a particular IP. For example `ip_ngrams_per_scene[10]['147.32.80.9']` gives the profiles in all sliding windows of the machine with IP *147.32.80.9* in *scenario 10*\n",
    "\n",
    "The infected IPs for every scenario are given in the respective README of the scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify 1 infected IP  for training\n",
    "train_infected_IPs_per_scene = {\n",
    "    9: '147.32.84.165',\n",
    "    10: '147.32.84.165',\n",
    "    11: '147.32.84.165',\n",
    "    12: '147.32.84.165'\n",
    "}   \n",
    "\n",
    "# identify other infected IPs for tuning the threshold\n",
    "infected_IPs_per_scene = {\n",
    "    9: [\n",
    "        # '147.32.84.165',\n",
    "        '147.32.84.191',\n",
    "        '147.32.84.192',\n",
    "        '147.32.84.193',\n",
    "        '147.32.84.204',\n",
    "        '147.32.84.205',\n",
    "        '147.32.84.206',\n",
    "        '147.32.84.207',\n",
    "        '147.32.84.208',\n",
    "        '147.32.84.209'\n",
    "        ],\n",
    "\n",
    "    10: [\n",
    "        # '147.32.84.165',\n",
    "        '147.32.84.191',\n",
    "        '147.32.84.192',\n",
    "        '147.32.84.193',\n",
    "        '147.32.84.204',\n",
    "        '147.32.84.205',\n",
    "        '147.32.84.206',\n",
    "        '147.32.84.207',\n",
    "        '147.32.84.208',\n",
    "        '147.32.84.209'\n",
    "    ],\n",
    "\n",
    "    11: [\n",
    "        # '147.32.84.165',\n",
    "        '147.32.84.191',\n",
    "        '147.32.84.192'\n",
    "    ],\n",
    "\n",
    "    12: [\n",
    "        # '147.32.84.165',\n",
    "        '147.32.84.191',\n",
    "        '147.32.84.192',\n",
    "    ]\n",
    "} \n",
    "\n",
    "# find all IPs for each scenario\n",
    "all_IPs_per_scene = {\n",
    "    9: list(ip_ngrams_per_scene[9].keys()),\n",
    "    10: list(ip_ngrams_per_scene[10].keys()),\n",
    "    11: list(ip_ngrams_per_scene[11].keys()),\n",
    "    12: list(ip_ngrams_per_scene[12].keys()),\n",
    "}\n",
    "\n",
    "for scene in selected_scenarios:\n",
    "    all_IPs_per_scene[scene].remove(train_infected_IPs_per_scene[scene])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "\n",
    "def compute_cosine_distance(ip_ngrams:dict, train_IP:str, infedted_IPs:list, all_IPs:list):\n",
    "    A = []  # set A: signatures for 1 infected IP \n",
    "    for signature in ip_ngrams[train_IP]:\n",
    "        A.append(signature)\n",
    "\n",
    "    true_labels = [] # labels for signatures \n",
    "    ip_distances = {}\n",
    "    for ip in tqdm(all_IPs):\n",
    "        if ip in infedted_IPs:\n",
    "            true_labels.append(1)\n",
    "        else:\n",
    "            true_labels.append(0)\n",
    "\n",
    "        sig_distances = []\n",
    "        for signature in ip_ngrams[ip]:\n",
    "            distances = []\n",
    "            for a in A:\n",
    "                distances.append(cosine_distances([a], [signature]))\n",
    "            # print(distances)\n",
    "            sig_distances.append(np.mean(distances))\n",
    "        # print(sig_distances)\n",
    "        ip_distances[ip] = sig_distances\n",
    "\n",
    "    return ip_distances, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For every scene find the signature distances from the known infected signatures.\n",
    "- also derive the true labels for the IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [08:23<30:47, 167.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3ad1e66046d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_scenarios\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         ip_distances, true_labels = compute_cosine_distance(\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mip_ngrams_per_scene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtrain_infected_IPs_per_scene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-333ee4c47fea>\u001b[0m in \u001b[0;36mcompute_cosine_distance\u001b[0;34m(ip_ngrams, train_IP, infedted_IPs, all_IPs)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m# print(distances)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0msig_distances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/q4/Cyber Data Analytics/project/cyber-data-analytics/env/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \"\"\"\n\u001b[1;32m    820\u001b[0m     \u001b[0;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/q4/Cyber Data Analytics/project/cyber-data-analytics/env/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/q4/Cyber Data Analytics/project/cyber-data-analytics/env/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    140\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                         estimator=estimator)\n\u001b[0;32m--> 142\u001b[0;31m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0m\u001b[1;32m    143\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                         estimator=estimator)\n",
      "\u001b[0;32m~/Documents/University/q4/Cyber Data Analytics/project/cyber-data-analytics/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    578\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/q4/Cyber Data Analytics/project/cyber-data-analytics/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# code for cosine similarity\n",
    "# from profiling import compute_cosine_distance\n",
    "\n",
    "RECOMPUTE_DISTANCES = True\n",
    "\n",
    "if RECOMPUTE_DISTANCES:\n",
    "    dist_per_scene = {}\n",
    "    labels_per_scene = {}\n",
    "\n",
    "    for scene in selected_scenarios:\n",
    "        ip_distances, true_labels = compute_cosine_distance(\n",
    "            ip_ngrams_per_scene[scene],\n",
    "            train_infected_IPs_per_scene[scene],\n",
    "            infected_IPs_per_scene[scene],\n",
    "            all_IPs_per_scene[scene])\n",
    "\n",
    "        dist_per_scene[scene] = ip_distances\n",
    "        labels_per_scene[scene] = true_labels\n",
    "\n",
    "    pickle.dump(dist_per_scene, open('data/utils/dist_per_scene.pkl', 'wb'))\n",
    "    pickle.dump(labels_per_scene, open('data/utils/labels_per_scene.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/utils/dist_per_scene.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b2fcebbe3768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read saved distances and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdist_per_scene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/utils/dist_per_scene.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels_per_scene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/utils/labels_per_scene.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/utils/dist_per_scene.pkl'"
     ]
    }
   ],
   "source": [
    "# read saved distances and labels\n",
    "dist_per_scene = pickle.load(open('data/utils/dist_per_scene.pkl', 'rb'))\n",
    "labels_per_scene = pickle.load(open('data/utils/labels_per_scene.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to clean out some IPs because they did not have enough records enabling **(sliding window + n-gram)** combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist_per_scene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d29516bff641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_scenarios\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mip\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfected_IPs_per_scene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mip\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_per_scene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0minfected_IPs_per_scene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist_per_scene' is not defined"
     ]
    }
   ],
   "source": [
    "# clean labels\n",
    "for scene in selected_scenarios:\n",
    "    for ip in infected_IPs_per_scene[scene]:\n",
    "        if ip not in list(dist_per_scene[scene].keys()):\n",
    "            infected_IPs_per_scene[scene].remove(ip)\n",
    "\n",
    "    if ip in all_IPs_per_scene[scene]:\n",
    "        if ip not in list(dist_per_scene[scene].keys()):\n",
    "            all_IPs_per_scene[scene].remove(ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting fucntion \n",
    "Now we will plot the data for each scenario to select the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ip_distance_mean_std:dict, infected_IPs:list, all_IPs, title:str, threshold=None):\n",
    "    # lets Plot the resulting decision boundary\n",
    "    fig, ax = plt.subplots(1,1, figsize=(14,5))\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('distance (log-scale)')\n",
    "    ax.set_ylim((-0.1,0.1))\n",
    "    values = np.array(list(ip_distance_mean_std.values()))\n",
    "    # print(values)\n",
    "    # X = values\n",
    "    # y = np.zeros((values.shape[0]))\n",
    "    # # ax.scatter(X, y, label='means') # plot means\n",
    "    # size = 250\n",
    "    \n",
    "    x = np.array([])\n",
    "    for ip in infected_IPs:\n",
    "        dists = np.array(ip_distance_mean_std[ip])\n",
    "        x = np.concatenate([x, dists])\n",
    "    x = np.array(x)\n",
    "    print(x.shape)\n",
    "    ax.scatter(x, np.zeros(len(x)), c='r', alpha=0.1, label='known botnet')\n",
    "    \n",
    "    x = np.array([])\n",
    "    for ip in all_IPs:\n",
    "        if ip not in infected_IPs:\n",
    "            dists = np.array(ip_distance_mean_std[ip])\n",
    "            x = np.concatenate([x, dists])\n",
    "    ax.scatter(x, np.zeros(len(x)), c='g', alpha=0.1, label='known normal')\n",
    "\n",
    "    if threshold is not None:\n",
    "        ax.axvline(threshold, ymin=-0, ymax=1, label='threshold', linestyle='--')\n",
    "    \n",
    "    # ax.set_xticks(range(1,10,1))\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold selection\n",
    "- We made the plots without the decision boundary i.e. just the means with label markers (red, green)\n",
    "- We decided the thresholds\n",
    "- then we plotted the one with the decision boundary **(what you see below)**\n",
    "\n",
    "***NO magic numbers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_per_scene = {\n",
    "    9:  3e-3,\n",
    "    10: 1.9e-2,\n",
    "    11: 1e-2,\n",
    "    12: 3.7e-2,\n",
    "}\n",
    "\n",
    "for scene in selected_scenarios:\n",
    "    plot(dist_per_scene[scene],\n",
    "         infected_IPs_per_scene[scene], \n",
    "         all_IPs_per_scene[scene], \n",
    "         'Scenario '+str(scene), \n",
    "         thresholds_per_scene[scene])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def predict(ip_distance_mean_std:dict, threshold:float):\n",
    "    pred = []\n",
    "    values = np.array(list(ip_distance_mean_std.values()))\n",
    "    for value in values:\n",
    "        if value[0] <= threshold:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4)\n",
    "fig.set_size_inches((20,5))\n",
    "for i in range(4):\n",
    "    scene = selected_scenarios[i]\n",
    "    pred = predict(dist_per_scene[scene], thresholds_per_scene[scene])\n",
    "    conf = confusion_matrix(labels_per_scene[scene], pred)\n",
    "    axs[i].set_title('Scenario ' + str(scene)+' prediction')\n",
    "    sns.heatmap(conf, square=True, annot=True, cmap=plt.cm.Oranges, ax = axs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('env': venv)",
   "language": "python",
   "name": "python38264bitenvvenv7b9860dd079f4740a146ad2038fa480b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
